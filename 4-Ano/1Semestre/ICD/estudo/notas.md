# Infraestrutura de Centro de Dados

## N√∫mero de p√°ginas dos slides

- infraestrutura - 9
- data storage - 44
- filesystems - 20
- dns - 14
- ntp - 7
- dhcp - 12
- reliability - 64
- data centers - 50

## Aulas te√≥ricas üìï

### Data storage

- https://www.youtube.com/watch?v=YqsVxCEpA0w - DAS vs NAS vs SAN
- https://www.youtube.com/watch?v=3yZDDr0JKVc - NAS vs SAN
- https://www.youtube.com/watch?v=U-OCdTeZLac - RAID 0, 1, 5 e 10

### DNS

- https://www.youtube.com/watch?v=mpQZVYPuDGU

### NTP

- https://www.youtube.com/watch?v=1GtySPUW-XA

### DHCP

- https://www.youtube.com/watch?v=e6-TaH5bkjo

### Data center basics

- **Resili√™ncia** - permite que a aplica√ß√£o continue com funcionalidade total ou parcial depois de uma ou mais falhas.
- **Reabilidade** - representa a probabilidade dum sistema n√£o encontrar nenhuma falha ao longo de um tempo. 
- **Disponibilidade** - habilidade dum sistema manter uma aplica√ß√£o a correr.
- **Facilidade de servi√ßo** - probabilidade dum servi√ßo ser completado com tempo limite.
- **Toler√¢ncia a faltas** - sistemas que conseguem correr com faltas de componentes.

---

## Aulas pr√°ticas üñ•

<details>
<summary>LVM</summary>

### Logic Volume Manager

O ***LVM*** √© uma ferramenta dispon√≠vel no kernel do Linux para gest√£o de volumes l√≥gicos. Ao originar uma camada de abstrac√ß√£o sobre o armazenamento f√≠sico, faz com que a cria√ß√£o e gest√£o de volumes l√≥gicos seja mais flex√≠vel e din√¢mica.

### Algumas vantagens
  
- Redimensionamento sem necessidade de refazer as parti√ß√µes.
- Nomes dos dispositivos personalizados pelo utilizador.
- Disk Striping, para aumento das velocidades de leitura e escrita (maior performance I/O).
- Mirroring volumes, para redund√¢ncia dos dados.
- Volume Snapshots, para backups consistentes ou para testar altera√ß√µes sem afectar os dados reais.

</details>

<details>
<summary>DRBD</summary>

### Distributed Replicated Block Device

O ***DRBD*** √© utilizado para constru√ß√£o de clusters de alta disponibilidade, onde os dados devem ser replicados em mais de um local.

Os dados s√£o gravados em dispositivos f√≠sicos comuns como HDs IDE e SATA, mas atrav√©s do m√≥dulo do DRBD √© criado um dispositivo de bloco, que gravar√° os dados via rede, num ou mais dispositivos f√≠sicos reais.

O DRBD trabalha como se fosse um RAID 1, mas em rede, ou seja, ter√°s o teu dispositivo espelhado de uma m√°quina para outra via rede.

### Vantagens

- Fornece alta disponibilidade e integridade de dados nos 2 servidores em caso de falha de hardware ou sistema.
- Garante a integridade dos dados refor√ßando *write consistency* no n√≥ prim√°rio e secund√°rio.

### Desvantagens

- Fornece apenas um m√©todo para duplicar dados entre os n√≥s. Os n√≥s secund√°rios n√£o podem usar o dispositivo DRBD enquanto os dados est√£o a ser replicados.
- N√£o pode fornecer escalabilidade, pois os n√≥s secund√°rios n√£o t√™m acesso aos dados secund√°rios.

### Uso recomendado

- Situa√ß√µes de alta disponibilidade em que o acesso simult√¢neo aos dados n√£o √© necess√°rio, mas o acesso instant√¢neo aos dados ativos no caso de falha do sistema ou hardware √© necess√°rio.

### Arquitetura

<img src="https://i.imgur.com/Bpv61hI.png" alt="drawing" width="500"/>

</details>

<details>
<summary>iSCSI Multipath</summary>

### Internet Small Computer System Interface

O ***iSCSI multipathing*** configura v√°rias rotas entre um servidor e seus dispositivos de armazenamento para manter uma conex√£o constante e **equilibrar a carga de tr√°fego**. O software *multipathing* lida com todas as solicita√ß√µes de entrada e sa√≠da e transmite-as no melhor caminho poss√≠vel. O tr√°fego dos servidores host √© transportado para o armazenamento compartilhado usando o protocolo *iSCSI* que empacota comandos *SCSI* em pacotes *iSCSI* e os transmite na rede *Ethernet*.

O *multipath iSCSI* fornece *failover*. No caso de falha de um caminho ou de qualquer um de seus componentes, o servidor seleciona outro caminho dispon√≠vel. Al√©m do *failover* de caminho, o balanceamento de carga de v√°rios caminhos distribui as cargas de armazenamento em v√°rios caminhos f√≠sicos para reduzir ou remover poss√≠veis *bottlenecks* (uma aplica√ß√£o possui um *bottleneck* quando est√° limitada por um √∫nico componente).

### Arquitetura

<img src="https://i.imgur.com/8dFEgyx.png" alt="drawing" width="500"/>

</details>

<details>
<summary>IPVS</summary>

### IP Virtual Server

O ***IPVS*** √© incorporado no *LVS* (Linux Virtual Server), onde √© executado num host e atua como um **balanceador de carga** na frente dum *cluster* de servidores reais. O *IPVS* pode direcionar solicita√ß√µes de servi√ßos baseados em *TCP* e *UDP* para os servidores reais e fazer com que os servi√ßos dos servidores reais apare√ßam como servi√ßos virtuais num √∫nico endere√ßo IP.

### Vantagens

- Facilidades a serem simplificadas, economia de espa√ßo, de tempo e custos.
- Gest√£o centralizada e compatibilidade total com aplicativos.
- Confiabilidade e disponibilidade - a falha do software n√£o afeta os outros servi√ßos.
- Balanceamento de carga: toda a m√°quina virtual √© encapsulada. Assim, torna-se f√°cil mudar a plataforma da m√°quina virtual e aumentar seu desempenho.
- Redu√ß√£o de custos com pessoal, energia e refrigera√ß√£o, uma vez que temos menos equipamento f√≠sico.

### Desvantagens

- Quando o servidor ficar offline, todos os sites hospedados por ele tamb√©m ficar√£o inativos.
- Gest√£o - ambientes virtuais precisam ser instanciados (criar inst√¢ncias em m√°quinas virtuais), monitorizados, configurados e guardados.
- Desempenho - n√£o existem m√©todos consolidados para medir o desempenho de ambientes virtualizados.
- Grande consumo de RAM j√° que cada m√°quina virtual ocupar√° uma √°rea separada da mesma, e grande consumo de disco uma vez que guarda todos os arquivos de cada sistema operativo instalado em cada uma das m√°quinas virtuais.

### Arquitetura

<img src="https://i.imgur.com/P711jay.png" alt="drawing" width="500"/>

</details>

<details>
<summary>Keepalived</summary>

### Keepalived

O ***Keepalived*** fornece estruturas para **balanceamento de carga** e **alta disponibilidade**. A estrutura de balanceamento de carga depende do conhecido e amplamente usado m√≥dulo de kernel **Linux Virtual Server (IPVS)**. *Keepalived* implementa um conjunto de *health checkers* para manter e gerir de forma din√¢mica e adaptativa *pools* de servidores com carga balanceada de acordo com sua "sa√∫de". A alta disponibilidade √© alcan√ßada pelo *Virtual Redundancy Routing Protocol* (VRRP). *VRRP* √© uma pe√ßa fundamental para *failover* do *router*.

### Arquitetura

<img src="https://i.imgur.com/oIUJcxp.png" alt="drawing" width="500"/>
</details>

<details>
<summary>High-Availability Cluster</summary>

### High-Availability Cluster

Um ***High-Availability Cluster*** √© um grupo de hosts que age como um √∫nico sistema e fornece tempo de atividade cont√≠nuo.

Os *High-Availability Clusters* costumam ser usados para fins de **balanceamento de carga**, **backup** e ***failover***. Para configurar adequadamente um HA, todos os hosts do cluster devem ter acesso ao mesmo armazenamento partilhado. Isso permite que as VMs num determinado host fa√ßam *failover* para outro host sem qualquer tempo de inatividade em caso de falha.

Os clusters de HA podem variar de dois a dezenas de n√≥s, mas os administradores de armazenamento devem ser cautelosos com o n√∫mero de VMs e hosts que adicionam a um cluster de HA porque muitos podem complicar o balanceamento de carga.

### Arquitetura

<img src="https://i.imgur.com/wr8kcD3.png" alt="drawing" width="500"/>
<img src="https://i.imgur.com/rIICFmb.png" alt="drawing" width="500"/>

</details>